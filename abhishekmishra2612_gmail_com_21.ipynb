{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "abhishekmishra2612@gmail.com_21.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tv_Dv_iLlOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKB8-qNYLlOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLL0cAh7oCH5",
        "colab_type": "code",
        "outputId": "bb4d0032-0c90-4da2-f387-794b9c8cdd44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY0BgON5LlOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activities are the class labels\n",
        "# It is a 6 class classification\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfQLP0XlLlO2",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfhH2nQULlO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IVziMOaLlPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM-jTN-8LlPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename =f'/content/drive/My Drive/Colab Notebooks/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhxtws0yLlPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename =f'/content/drive/My Drive/Colab Notebooks/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XD6KoyLlPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKjMVjRBLlPl",
        "colab_type": "code",
        "outputId": "518c162d-1594-4da5-9dca-e4897c7bb744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs_v58ATLlPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuring a session\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwyvcoUBLlP5",
        "colab_type": "code",
        "outputId": "aa459fd8-8151-4e02-d9b1-407eac8379f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Keras\n",
        "from keras import backend as K\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPqUvVglLlQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQlhHaYLlQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "n_hidden = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQ6wBSYLlQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnBJoiu1LlQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSGqHD5vQGRF",
        "colab_type": "code",
        "outputId": "4fa2354b-465c-4f5e-cf0a-5bf90cbee6f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 128, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llKaAAPWLlQm",
        "colab_type": "code",
        "outputId": "e004e991-e8ab-40fe-91a6-a1841f08bb38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = _count_classes(Y_train)\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjmfRiZqLlQw",
        "colab_type": "text"
      },
      "source": [
        "- Defining the Architecture of LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSHor4okFNO0",
        "colab_type": "text"
      },
      "source": [
        "# Model-1 with 16 LSTM cells, Dropout rate=0.2 and 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6oZaUYbLlQy",
        "colab_type": "code",
        "outputId": "16f360dd-877f-4fe5-d53c-9628bd58a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(16, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 16)                1664      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 102       \n",
            "=================================================================\n",
            "Total params: 1,766\n",
            "Trainable params: 1,766\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA932zNRLlQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv2NpjeuLlQ-",
        "colab_type": "code",
        "outputId": "8550c1a4-6cf8-48d4-b083-02555d9b7103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model\n",
        "\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 45s 6ms/step - loss: 1.3948 - acc: 0.4199 - val_loss: 1.2082 - val_acc: 0.5008\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 1.0421 - acc: 0.5609 - val_loss: 1.2011 - val_acc: 0.4947\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.9104 - acc: 0.6340 - val_loss: 0.9751 - val_acc: 0.6597\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 42s 6ms/step - loss: 0.7810 - acc: 0.6885 - val_loss: 0.9200 - val_acc: 0.5704\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 42s 6ms/step - loss: 0.6623 - acc: 0.7205 - val_loss: 0.7262 - val_acc: 0.7072\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 42s 6ms/step - loss: 0.5569 - acc: 0.7692 - val_loss: 0.6556 - val_acc: 0.7302\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6572 - acc: 0.6997 - val_loss: 0.7886 - val_acc: 0.6339\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6584 - acc: 0.6741 - val_loss: 0.7442 - val_acc: 0.6518\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6292 - acc: 0.6911 - val_loss: 0.7215 - val_acc: 0.6671\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6034 - acc: 0.7160 - val_loss: 0.6814 - val_acc: 0.7011\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.5431 - acc: 0.7539 - val_loss: 0.5983 - val_acc: 0.7448\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.5372 - acc: 0.7695 - val_loss: 0.5714 - val_acc: 0.7482\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 40s 6ms/step - loss: 0.4515 - acc: 0.7956 - val_loss: 0.5763 - val_acc: 0.7594\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.4245 - acc: 0.8109 - val_loss: 0.5634 - val_acc: 0.7767\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.3961 - acc: 0.8428 - val_loss: 0.5188 - val_acc: 0.7937\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3733 - acc: 0.8606 - val_loss: 0.5523 - val_acc: 0.7883\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3674 - acc: 0.8682 - val_loss: 0.4951 - val_acc: 0.8222\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3293 - acc: 0.8900 - val_loss: 0.5035 - val_acc: 0.8212\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2978 - acc: 0.9056 - val_loss: 0.4864 - val_acc: 0.8541\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2815 - acc: 0.9045 - val_loss: 0.4648 - val_acc: 0.8514\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2615 - acc: 0.9155 - val_loss: 0.4280 - val_acc: 0.8524\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2729 - acc: 0.9083 - val_loss: 0.4163 - val_acc: 0.8588\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2555 - acc: 0.9187 - val_loss: 0.4376 - val_acc: 0.8507\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2304 - acc: 0.9245 - val_loss: 0.4046 - val_acc: 0.8643\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2160 - acc: 0.9283 - val_loss: 0.4156 - val_acc: 0.8575\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2038 - acc: 0.9328 - val_loss: 0.4271 - val_acc: 0.8738\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2062 - acc: 0.9276 - val_loss: 0.4255 - val_acc: 0.8714\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2103 - acc: 0.9278 - val_loss: 0.4840 - val_acc: 0.8412\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2090 - acc: 0.9287 - val_loss: 0.3892 - val_acc: 0.8826\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1761 - acc: 0.9370 - val_loss: 0.4038 - val_acc: 0.8795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bddaa1e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vllzQYmCLlRG",
        "colab_type": "code",
        "outputId": "3b791298-1069-489c-83a4-a70f98be62ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss and Accuracy on test dataset.\")\n",
        "print(\"Loss =\",score[0],\"Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                27\n",
            "SITTING                  0      366  ...                   1                 3\n",
            "STANDING                 0       59  ...                   0                 3\n",
            "WALKING                  0        0  ...                  38                 4\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 372                 4\n",
            "WALKING_UPSTAIRS         0        0  ...                   2               421\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 6s 2ms/step\n",
            "Loss and Accuracy on test dataset.\n",
            "Loss = 0.40384531464910595 Accuracy = 0.8795385137427892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgCH5x1r5E6",
        "colab_type": "text"
      },
      "source": [
        "#Model-2 with 32 LSTM cells,Dropout Rate is 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvqszQGPgruB",
        "colab_type": "code",
        "outputId": "d16f4a28-858a-483a-95bd-1122cf69a1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model_1 = Sequential()\n",
        "# Configuring the parameters\n",
        "model_1.add(LSTM(32, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model_1.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model_1.add(Dense(n_classes, activation='softmax'))\n",
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSw2jM24gr0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWufsbcBgr9M",
        "colab_type": "code",
        "outputId": "a2fc87af-e603-4026-c4de-ee67831d9c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_1.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 42s 6ms/step - loss: 1.3216 - acc: 0.4324 - val_loss: 1.0653 - val_acc: 0.5399\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 43s 6ms/step - loss: 0.9398 - acc: 0.5877 - val_loss: 1.1340 - val_acc: 0.5724\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 43s 6ms/step - loss: 1.0416 - acc: 0.5611 - val_loss: 0.9083 - val_acc: 0.5993\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 43s 6ms/step - loss: 0.9246 - acc: 0.6016 - val_loss: 1.0497 - val_acc: 0.5283\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 43s 6ms/step - loss: 0.8487 - acc: 0.6232 - val_loss: 0.7916 - val_acc: 0.6566\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.7261 - acc: 0.6661 - val_loss: 0.8382 - val_acc: 0.6580\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.7631 - acc: 0.6522 - val_loss: 0.7974 - val_acc: 0.6909\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.7018 - acc: 0.6814 - val_loss: 0.7375 - val_acc: 0.6936\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6387 - acc: 0.7148 - val_loss: 0.7002 - val_acc: 0.7201\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.5935 - acc: 0.7519 - val_loss: 1.1636 - val_acc: 0.6247\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.6734 - acc: 0.7406 - val_loss: 0.6133 - val_acc: 0.7794\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 42s 6ms/step - loss: 0.5069 - acc: 0.8130 - val_loss: 0.5273 - val_acc: 0.8073\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.4047 - acc: 0.8565 - val_loss: 0.4694 - val_acc: 0.8531\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3499 - acc: 0.8840 - val_loss: 0.4832 - val_acc: 0.8371\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3411 - acc: 0.8912 - val_loss: 0.4211 - val_acc: 0.8751\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 40s 6ms/step - loss: 0.3942 - acc: 0.8946 - val_loss: 1.6010 - val_acc: 0.6919\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.4724 - acc: 0.8624 - val_loss: 0.4152 - val_acc: 0.8585\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3113 - acc: 0.9064 - val_loss: 0.5047 - val_acc: 0.8375\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2788 - acc: 0.9149 - val_loss: 0.3342 - val_acc: 0.8741\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2447 - acc: 0.9232 - val_loss: 0.5294 - val_acc: 0.8347\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2119 - acc: 0.9320 - val_loss: 0.4037 - val_acc: 0.8901\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 40s 6ms/step - loss: 0.2016 - acc: 0.9354 - val_loss: 0.3697 - val_acc: 0.8873\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2023 - acc: 0.9338 - val_loss: 0.4783 - val_acc: 0.8694\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.7834 - acc: 0.8300 - val_loss: 0.6103 - val_acc: 0.8500\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3543 - acc: 0.8916 - val_loss: 0.4554 - val_acc: 0.8541\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2891 - acc: 0.9134 - val_loss: 0.4013 - val_acc: 0.8839\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2701 - acc: 0.9165 - val_loss: 0.3641 - val_acc: 0.8870\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2868 - acc: 0.9042 - val_loss: 0.4508 - val_acc: 0.8575\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3096 - acc: 0.8893 - val_loss: 0.4038 - val_acc: 0.8755\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2798 - acc: 0.8974 - val_loss: 0.4929 - val_acc: 0.8656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bdd76f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpSGbkp2gsC8",
        "colab_type": "code",
        "outputId": "fab08739-90b0-4049-98af-c049514ce3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model_1.predict(X_test)))\n",
        "\n",
        "score = model_1.evaluate(X_test, Y_test)\n",
        "print(\"Loss and Accuracy on test dataset.\")\n",
        "print(\"Loss =\",score[0],\"Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                27\n",
            "SITTING                 65      344  ...                   0                 4\n",
            "STANDING                 0      100  ...                   0                 0\n",
            "WALKING                  0        0  ...                  30                 7\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 415                 5\n",
            "WALKING_UPSTAIRS         0        0  ...                  10               419\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 6s 2ms/step\n",
            "Loss and Accuracy on test dataset.\n",
            "Loss = 0.4929030795109499 Accuracy = 0.8656260604004072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHbyRl4tsOSV",
        "colab_type": "text"
      },
      "source": [
        "#Model-3 with 64 LSTM cells and Droput Rate is 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L-YFGKBgsLF",
        "colab_type": "code",
        "outputId": "5fc966e3-c616-4cb0-9054-c7e0d5fcbc9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model_2 = Sequential()\n",
        "# Configuring the parameters\n",
        "model_2.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model_2.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model_2.add(Dense(n_classes, activation='softmax'))\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 64)                18944     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 19,334\n",
            "Trainable params: 19,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbbu6ex0gsRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahfKRir-gsXu",
        "colab_type": "code",
        "outputId": "07a6b7e3-4f61-4705-f52e-27d4cb62f954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model_2.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/50\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 1.2999 - acc: 0.4479 - val_loss: 1.1349 - val_acc: 0.5375\n",
            "Epoch 2/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.9616 - acc: 0.5948 - val_loss: 0.9573 - val_acc: 0.6166\n",
            "Epoch 3/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.7211 - acc: 0.7021 - val_loss: 0.6782 - val_acc: 0.7431\n",
            "Epoch 4/50\n",
            "7352/7352 [==============================] - 53s 7ms/step - loss: 0.5939 - acc: 0.7855 - val_loss: 0.8388 - val_acc: 0.6875\n",
            "Epoch 5/50\n",
            "7352/7352 [==============================] - 53s 7ms/step - loss: 0.4679 - acc: 0.8371 - val_loss: 0.4386 - val_acc: 0.8636\n",
            "Epoch 6/50\n",
            "7352/7352 [==============================] - 53s 7ms/step - loss: 0.3800 - acc: 0.8803 - val_loss: 1.4179 - val_acc: 0.5205\n",
            "Epoch 7/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.6551 - acc: 0.7501 - val_loss: 0.4991 - val_acc: 0.8157\n",
            "Epoch 8/50\n",
            "7352/7352 [==============================] - 53s 7ms/step - loss: 0.3449 - acc: 0.8697 - val_loss: 0.4681 - val_acc: 0.8347\n",
            "Epoch 9/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.3044 - acc: 0.8938 - val_loss: 0.4032 - val_acc: 0.8483\n",
            "Epoch 10/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2328 - acc: 0.9176 - val_loss: 0.3256 - val_acc: 0.8880\n",
            "Epoch 11/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2803 - acc: 0.8974 - val_loss: 0.3920 - val_acc: 0.8412\n",
            "Epoch 12/50\n",
            "7352/7352 [==============================] - 55s 8ms/step - loss: 0.3205 - acc: 0.9019 - val_loss: 0.3767 - val_acc: 0.8816\n",
            "Epoch 13/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2371 - acc: 0.9181 - val_loss: 0.3172 - val_acc: 0.8935\n",
            "Epoch 14/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1805 - acc: 0.9380 - val_loss: 0.2606 - val_acc: 0.9063\n",
            "Epoch 15/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1572 - acc: 0.9414 - val_loss: 0.2776 - val_acc: 0.8985\n",
            "Epoch 16/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1515 - acc: 0.9450 - val_loss: 0.3016 - val_acc: 0.9023\n",
            "Epoch 17/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1696 - acc: 0.9411 - val_loss: 0.2734 - val_acc: 0.9033\n",
            "Epoch 18/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1746 - acc: 0.9382 - val_loss: 0.2598 - val_acc: 0.9080\n",
            "Epoch 19/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1545 - acc: 0.9421 - val_loss: 0.4909 - val_acc: 0.8829\n",
            "Epoch 20/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1863 - acc: 0.9385 - val_loss: 0.2167 - val_acc: 0.9172\n",
            "Epoch 21/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1692 - acc: 0.9399 - val_loss: 0.2599 - val_acc: 0.9097\n",
            "Epoch 22/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1568 - acc: 0.9416 - val_loss: 0.2864 - val_acc: 0.8924\n",
            "Epoch 23/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1347 - acc: 0.9471 - val_loss: 0.2357 - val_acc: 0.9175\n",
            "Epoch 24/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1476 - acc: 0.9412 - val_loss: 0.2490 - val_acc: 0.9118\n",
            "Epoch 25/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1370 - acc: 0.9444 - val_loss: 0.2233 - val_acc: 0.9182\n",
            "Epoch 26/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1400 - acc: 0.9486 - val_loss: 0.2659 - val_acc: 0.9158\n",
            "Epoch 27/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2234 - acc: 0.9210 - val_loss: 0.3223 - val_acc: 0.8755\n",
            "Epoch 28/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1836 - acc: 0.9353 - val_loss: 0.2913 - val_acc: 0.9087\n",
            "Epoch 29/50\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1410 - acc: 0.9446 - val_loss: 0.1948 - val_acc: 0.9223\n",
            "Epoch 30/50\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1292 - acc: 0.9514 - val_loss: 0.2266 - val_acc: 0.9216\n",
            "Epoch 31/50\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1348 - acc: 0.9484 - val_loss: 0.2620 - val_acc: 0.9094\n",
            "Epoch 32/50\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1292 - acc: 0.9471 - val_loss: 0.2788 - val_acc: 0.9199\n",
            "Epoch 33/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1413 - acc: 0.9472 - val_loss: 0.2207 - val_acc: 0.9216\n",
            "Epoch 34/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1297 - acc: 0.9483 - val_loss: 0.1790 - val_acc: 0.9345\n",
            "Epoch 35/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1216 - acc: 0.9524 - val_loss: 0.2301 - val_acc: 0.9277\n",
            "Epoch 36/50\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1130 - acc: 0.9557 - val_loss: 0.2078 - val_acc: 0.9203\n",
            "Epoch 37/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1136 - acc: 0.9546 - val_loss: 0.2168 - val_acc: 0.9233\n",
            "Epoch 38/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1235 - acc: 0.9554 - val_loss: 0.3000 - val_acc: 0.9070\n",
            "Epoch 39/50\n",
            "7352/7352 [==============================] - 55s 8ms/step - loss: 0.1707 - acc: 0.9370 - val_loss: 0.2319 - val_acc: 0.9131\n",
            "Epoch 40/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1255 - acc: 0.9527 - val_loss: 0.2234 - val_acc: 0.9223\n",
            "Epoch 41/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1660 - acc: 0.9400 - val_loss: 0.2909 - val_acc: 0.8982\n",
            "Epoch 42/50\n",
            "7352/7352 [==============================] - 55s 8ms/step - loss: 0.1952 - acc: 0.9415 - val_loss: 0.2864 - val_acc: 0.9084\n",
            "Epoch 43/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1351 - acc: 0.9523 - val_loss: 0.2078 - val_acc: 0.9230\n",
            "Epoch 44/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1260 - acc: 0.9517 - val_loss: 0.2272 - val_acc: 0.9186\n",
            "Epoch 45/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1219 - acc: 0.9535 - val_loss: 0.2167 - val_acc: 0.9175\n",
            "Epoch 46/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1158 - acc: 0.9559 - val_loss: 0.1967 - val_acc: 0.9196\n",
            "Epoch 47/50\n",
            "7352/7352 [==============================] - 55s 8ms/step - loss: 0.1130 - acc: 0.9542 - val_loss: 0.2233 - val_acc: 0.9213\n",
            "Epoch 48/50\n",
            "7352/7352 [==============================] - 55s 7ms/step - loss: 0.1123 - acc: 0.9536 - val_loss: 0.2429 - val_acc: 0.9243\n",
            "Epoch 49/50\n",
            "7352/7352 [==============================] - 55s 8ms/step - loss: 0.1109 - acc: 0.9546 - val_loss: 0.2444 - val_acc: 0.9220\n",
            "Epoch 50/50\n",
            "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1120 - acc: 0.9543 - val_loss: 0.2100 - val_acc: 0.9203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52f77bf668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF7isLHqgsc9",
        "colab_type": "code",
        "outputId": "e07304e0-8c66-44dc-e337-9c1d327647de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model_2.predict(X_test)))\n",
        "\n",
        "score = model_2.evaluate(X_test, Y_test)\n",
        "print(\"Loss and Accuracy on test dataset.\")\n",
        "print(\"Loss =\",score[0],\"Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 478        0  ...                   6                53\n",
            "SITTING                  0      389  ...                   1                24\n",
            "STANDING                 0       82  ...                   0                 8\n",
            "WALKING                  0        0  ...                  24                11\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 366                19\n",
            "WALKING_UPSTAIRS         0        0  ...                  28               412\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 9s 3ms/step\n",
            "Loss and Accuracy on test dataset.\n",
            "Loss = 0.43390871153105953 Accuracy = 0.8646080760095012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzKceGvOpXeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if(score[1]>=0.93):   \n",
        "   model_2.save(\"/content/drive/My Drive/HAR_Model_2_91.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROFv7Kq_seLQ",
        "colab_type": "text"
      },
      "source": [
        "#Model-4 with 128 LSTM cells and Dropout Rate is 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WswY7XmlgsmH",
        "colab_type": "code",
        "outputId": "5b967e69-0020-4258-978e-5765d10c3e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model_3 = Sequential()\n",
        "# Configuring the parameters\n",
        "model_3.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model_3.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model_3.add(Dense(n_classes, activation='softmax'))\n",
        "model_3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 128)               70656     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 71,430\n",
            "Trainable params: 71,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKf6a8fCgsqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model_3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFCb9ZS_gsjL",
        "colab_type": "code",
        "outputId": "363ddcb6-486e-4efe-9a68-89fccf19f5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "source": [
        "model_3.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/40\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 1.3604 - acc: 0.4006 - val_loss: 1.7912 - val_acc: 0.3828\n",
            "Epoch 2/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 1.2124 - acc: 0.4971 - val_loss: 1.2886 - val_acc: 0.4221\n",
            "Epoch 3/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.9638 - acc: 0.5903 - val_loss: 0.9426 - val_acc: 0.5959\n",
            "Epoch 4/40\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.7568 - acc: 0.6933 - val_loss: 1.3377 - val_acc: 0.5327\n",
            "Epoch 5/40\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.7028 - acc: 0.7335 - val_loss: 0.6580 - val_acc: 0.7594\n",
            "Epoch 6/40\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.4681 - acc: 0.8385 - val_loss: 0.6420 - val_acc: 0.7961\n",
            "Epoch 7/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.3232 - acc: 0.8878 - val_loss: 0.4251 - val_acc: 0.8592\n",
            "Epoch 8/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.2739 - acc: 0.9040 - val_loss: 0.4528 - val_acc: 0.8361\n",
            "Epoch 9/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.2288 - acc: 0.9155 - val_loss: 0.3366 - val_acc: 0.8792\n",
            "Epoch 10/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1933 - acc: 0.9260 - val_loss: 0.3427 - val_acc: 0.8829\n",
            "Epoch 11/40\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.7515 - acc: 0.7652 - val_loss: 0.4700 - val_acc: 0.8286\n",
            "Epoch 12/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.3243 - acc: 0.8932 - val_loss: 0.3502 - val_acc: 0.8999\n",
            "Epoch 13/40\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1918 - acc: 0.9342 - val_loss: 0.3662 - val_acc: 0.8945\n",
            "Epoch 14/40\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.2031 - acc: 0.9323 - val_loss: 1.1776 - val_acc: 0.7706\n",
            "Epoch 15/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.3043 - acc: 0.8966 - val_loss: 0.3542 - val_acc: 0.9043\n",
            "Epoch 16/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1977 - acc: 0.9283 - val_loss: 0.5597 - val_acc: 0.8358\n",
            "Epoch 17/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.2060 - acc: 0.9240 - val_loss: 0.3068 - val_acc: 0.9114\n",
            "Epoch 18/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1486 - acc: 0.9411 - val_loss: 0.2916 - val_acc: 0.8965\n",
            "Epoch 19/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1439 - acc: 0.9411 - val_loss: 0.3116 - val_acc: 0.8968\n",
            "Epoch 20/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1513 - acc: 0.9381 - val_loss: 0.3795 - val_acc: 0.8999\n",
            "Epoch 21/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1568 - acc: 0.9430 - val_loss: 0.4053 - val_acc: 0.8975\n",
            "Epoch 22/40\n",
            "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1387 - acc: 0.9456 - val_loss: 0.3511 - val_acc: 0.9094\n",
            "Epoch 23/40\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1649 - acc: 0.9347 - val_loss: 0.3672 - val_acc: 0.8897\n",
            "Epoch 24/40\n",
            "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1809 - acc: 0.9309 - val_loss: 0.3216 - val_acc: 0.9074\n",
            "Epoch 25/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1499 - acc: 0.9431 - val_loss: 0.2753 - val_acc: 0.9046\n",
            "Epoch 26/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1200 - acc: 0.9510 - val_loss: 0.3205 - val_acc: 0.9057\n",
            "Epoch 27/40\n",
            "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1363 - acc: 0.9461 - val_loss: 0.3414 - val_acc: 0.9050\n",
            "Epoch 28/40\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1299 - acc: 0.9483 - val_loss: 0.3446 - val_acc: 0.8975\n",
            "Epoch 29/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1195 - acc: 0.9527 - val_loss: 0.3282 - val_acc: 0.9145\n",
            "Epoch 30/40\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1141 - acc: 0.9517 - val_loss: 0.3564 - val_acc: 0.9182\n",
            "Epoch 31/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1227 - acc: 0.9493 - val_loss: 0.3124 - val_acc: 0.9162\n",
            "Epoch 32/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1215 - acc: 0.9542 - val_loss: 0.3295 - val_acc: 0.9165\n",
            "Epoch 33/40\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1340 - acc: 0.9501 - val_loss: 0.3460 - val_acc: 0.9131\n",
            "Epoch 34/40\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.4001 - acc: 0.8764 - val_loss: 0.3042 - val_acc: 0.9023\n",
            "Epoch 35/40\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1900 - acc: 0.9340 - val_loss: 0.3430 - val_acc: 0.9026\n",
            "Epoch 36/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1341 - acc: 0.9505 - val_loss: 0.3339 - val_acc: 0.9030\n",
            "Epoch 37/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1344 - acc: 0.9486 - val_loss: 0.3378 - val_acc: 0.9128\n",
            "Epoch 38/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1351 - acc: 0.9490 - val_loss: 0.3543 - val_acc: 0.9050\n",
            "Epoch 39/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1617 - acc: 0.9382 - val_loss: 0.3161 - val_acc: 0.9033\n",
            "Epoch 40/40\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1323 - acc: 0.9491 - val_loss: 0.3806 - val_acc: 0.9074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f262b360550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVAJ0uY3gshG",
        "colab_type": "code",
        "outputId": "a365b487-f530-4480-993c-44c709c1b01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model_3.predict(X_test)))\n",
        "\n",
        "score = model_3.evaluate(X_test, Y_test)\n",
        "print(\"Loss and Accuracy on test dataset.\")\n",
        "print(\"Loss =\",score[0],\"Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                27\n",
            "SITTING                  0      377  ...                   0                 3\n",
            "STANDING                 0       75  ...                   0                 1\n",
            "WALKING                  0        0  ...                  29                 6\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 406                14\n",
            "WALKING_UPSTAIRS         0        0  ...                   5               464\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 8s 3ms/step\n",
            "Loss and Accuracy on test dataset.\n",
            "Loss = 0.38057940114042443 Accuracy = 0.9073634204275535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyzPDRzwssUk",
        "colab_type": "text"
      },
      "source": [
        "#Models with 64 LSTM cells and Dropout Rate range from 0.2 to 0.8\n",
        "#Tuning the Dropout Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0se-mA4QgsPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Loss=[]\n",
        "Accuracy=[]\n",
        "for dr in [0.2,0.3,0.4,0.5,0.6,0.7,0.8]:\n",
        "  model_4=Sequential()\n",
        "  model_4.add(LSTM(64,input_shape=(timesteps,input_dim)))\n",
        "  model_4.add(Dropout(dr))\n",
        "  model_4.add(Dense(n_classes,activation=\"softmax\"))\n",
        "  model_4.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "  model_4.fit(X_train,Y_train,verbose=0,batch_size=batch_size,epochs=40,validation_data=(X_test,Y_test))\n",
        "  score=model_4.evaluate(X_test,Y_test,verbose=0)\n",
        "  Loss.append(score[0])\n",
        "  Accuracy.append(score[1]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYLeC-p2gsJV",
        "colab_type": "code",
        "outputId": "b5b8ad33-db94-452e-c9ed-f56798caf851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for value in zip([0.2,0.3,0.4,0.5,0.6,0.7,0.8],Loss,Accuracy):\n",
        "  print(\"Dropout  Rate =\",value[0],\" Loss =\",value[1],\" Accuracy =\",value[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dropout  Rate = 0.2  Loss = 0.2760419166115642  Accuracy = 0.9066847641669494\n",
            "Dropout  Rate = 0.3  Loss = 0.31988952920646435  Accuracy = 0.9015948422124194\n",
            "Dropout  Rate = 0.4  Loss = 0.33839115369865086  Accuracy = 0.9141499830335935\n",
            "Dropout  Rate = 0.5  Loss = 0.29408313663332547  Accuracy = 0.9110960298608755\n",
            "Dropout  Rate = 0.6  Loss = 0.33349750262054534  Accuracy = 0.9029521547336274\n",
            "Dropout  Rate = 0.7  Loss = 0.49674681740714044  Accuracy = 0.8534102477095351\n",
            "Dropout  Rate = 0.8  Loss = 0.46191621326802856  Accuracy = 0.8914149983033594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zfzBdYRzctl",
        "colab_type": "code",
        "outputId": "fad5a556-5016-4806-a4a0-166de56e4657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([0.2,0.3,0.4,0.5,0.6,0.7,0.8],Accuracy)\n",
        "plt.scatter([0.2,0.3,0.4,0.5,0.6,0.7,0.8],Accuracy)\n",
        "plt.title(\"Plot between Dropout rate and Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Dropout Rate\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcYYvyxBGGOM8ev/AyD+cCmdcne5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MroCtTrXtX62",
        "colab_type": "text"
      },
      "source": [
        "#Model with 2 LSTM layer and each LSTM layer contain 32 cells and keeping the dropout rate for both kayers is 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NClWqzlbszEc",
        "colab_type": "code",
        "outputId": "3db8b086-1601-4d4c-f11f-7abc5565e535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model_0 = Sequential()\n",
        "# Configuring the parameters\n",
        "model_0.add(LSTM(32, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "model_0.add(Dropout(0.4))\n",
        "model_0.add(LSTM(32))\n",
        "model_0.add(Dropout(0.4))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model_0.add(Dense(n_classes, activation='softmax'))\n",
        "model_0.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128, 32)           5376      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 13,894\n",
            "Trainable params: 13,894\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLHiK7AbtgCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSAYJrOhtpUa",
        "colab_type": "code",
        "outputId": "a2fe968f-64c8-488c-abb3-581b0f0e658c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "source": [
        "model_0.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 1.1912 - acc: 0.5008 - val_loss: 1.0537 - val_acc: 0.5412\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.6955 - acc: 0.7433 - val_loss: 0.5747 - val_acc: 0.8181\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.3794 - acc: 0.8893 - val_loss: 0.5413 - val_acc: 0.8439\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 86s 12ms/step - loss: 0.2635 - acc: 0.9193 - val_loss: 0.5246 - val_acc: 0.8599\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2891 - acc: 0.9055 - val_loss: 0.4666 - val_acc: 0.8497\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 92s 12ms/step - loss: 0.2375 - acc: 0.9208 - val_loss: 0.6414 - val_acc: 0.7811\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 92s 12ms/step - loss: 0.2719 - acc: 0.9071 - val_loss: 0.4570 - val_acc: 0.8470\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1938 - acc: 0.9338 - val_loss: 0.4322 - val_acc: 0.8734\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1768 - acc: 0.9381 - val_loss: 0.4277 - val_acc: 0.8836\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1953 - acc: 0.9343 - val_loss: 0.3742 - val_acc: 0.8931\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1550 - acc: 0.9455 - val_loss: 0.4289 - val_acc: 0.8873\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1673 - acc: 0.9407 - val_loss: 0.4259 - val_acc: 0.8853\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1329 - acc: 0.9480 - val_loss: 0.3938 - val_acc: 0.8901\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1319 - acc: 0.9498 - val_loss: 0.9890 - val_acc: 0.7065\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1733 - acc: 0.9323 - val_loss: 0.4030 - val_acc: 0.8846\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1389 - acc: 0.9461 - val_loss: 0.3991 - val_acc: 0.8880\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1313 - acc: 0.9478 - val_loss: 0.3794 - val_acc: 0.8890\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1592 - acc: 0.9419 - val_loss: 0.4004 - val_acc: 0.8945\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1449 - acc: 0.9442 - val_loss: 0.4816 - val_acc: 0.8918\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1407 - acc: 0.9467 - val_loss: 0.3615 - val_acc: 0.9026\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1438 - acc: 0.9455 - val_loss: 0.4310 - val_acc: 0.8979\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1266 - acc: 0.9489 - val_loss: 0.4830 - val_acc: 0.8935\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1270 - acc: 0.9475 - val_loss: 0.4733 - val_acc: 0.8965\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1166 - acc: 0.9538 - val_loss: 0.5265 - val_acc: 0.8985\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1230 - acc: 0.9508 - val_loss: 0.4847 - val_acc: 0.8965\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1150 - acc: 0.9533 - val_loss: 0.5175 - val_acc: 0.8948\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1284 - acc: 0.9550 - val_loss: 0.4823 - val_acc: 0.8985\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1905 - acc: 0.9377 - val_loss: 0.3469 - val_acc: 0.8972\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1566 - acc: 0.9418 - val_loss: 0.3541 - val_acc: 0.8931\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1314 - acc: 0.9494 - val_loss: 0.3706 - val_acc: 0.9070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe532db0550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjTRb5DHt00l",
        "colab_type": "code",
        "outputId": "874f7351-fd2f-4040-bc46-282cbf907c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model_0.predict(X_test)))\n",
        "\n",
        "score = model_0.evaluate(X_test, Y_test)\n",
        "print(\"Loss and Accuracy on test dataset.\")\n",
        "print(\"Loss =\",score[0],\"Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                27\n",
            "SITTING                  0      417  ...                   0                12\n",
            "STANDING                 0      109  ...                   0                 3\n",
            "WALKING                  0        0  ...                  34                 4\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 415                 2\n",
            "WALKING_UPSTAIRS         0        2  ...                  11               453\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 12s 4ms/step\n",
            "Loss and Accuracy on test dataset.\n",
            "Loss = 0.3705637179395716 Accuracy = 0.9070240922972514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJUx5aBctzuX",
        "colab_type": "text"
      },
      "source": [
        "#Model with 2 LSTM layer and each layer contain 64 LSTM cells and dropout rate for both layer is 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdm00l49gsBa",
        "colab_type": "code",
        "outputId": "27fd126b-a307-43e0-d448-ae736860122f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model_5 = Sequential()\n",
        "# Configuring the parameters\n",
        "model_5.add(LSTM(64, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "model_5.add(Dropout(0.5))\n",
        "#Adding another LSTM layer\n",
        "model_5.add(LSTM(64))\n",
        "#adding Dropout Layer\n",
        "model_5.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model_5.add(Dense(n_classes, activation='softmax'))\n",
        "model_5.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128, 64)           18944     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 52,358\n",
            "Trainable params: 52,358\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOQqoIv8gr6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_5.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha9BiRUMRC1y",
        "colab_type": "code",
        "outputId": "32258915-29a3-4047-d267-0e4394de82e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_5.fit(X_train,Y_train,verbose=1,batch_size=batch_size,epochs=50,validation_data=(X_test,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/50\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 1.0967 - acc: 0.5325 - val_loss: 0.7467 - val_acc: 0.6916\n",
            "Epoch 2/50\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.6820 - acc: 0.7088 - val_loss: 0.6000 - val_acc: 0.7662\n",
            "Epoch 3/50\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.4985 - acc: 0.8047 - val_loss: 0.5971 - val_acc: 0.7367\n",
            "Epoch 4/50\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.4451 - acc: 0.8048 - val_loss: 0.5267 - val_acc: 0.8093\n",
            "Epoch 5/50\n",
            "7352/7352 [==============================] - 86s 12ms/step - loss: 0.5469 - acc: 0.7885 - val_loss: 0.7265 - val_acc: 0.7228\n",
            "Epoch 6/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.4018 - acc: 0.8576 - val_loss: 0.6966 - val_acc: 0.7648\n",
            "Epoch 7/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.3235 - acc: 0.8938 - val_loss: 0.4196 - val_acc: 0.8599\n",
            "Epoch 8/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.2896 - acc: 0.9086 - val_loss: 0.3864 - val_acc: 0.8605\n",
            "Epoch 9/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1877 - acc: 0.9342 - val_loss: 0.4038 - val_acc: 0.8476\n",
            "Epoch 10/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1668 - acc: 0.9392 - val_loss: 0.3166 - val_acc: 0.8958\n",
            "Epoch 11/50\n",
            "7352/7352 [==============================] - 85s 11ms/step - loss: 0.2259 - acc: 0.9275 - val_loss: 0.2898 - val_acc: 0.9050\n",
            "Epoch 12/50\n",
            "7352/7352 [==============================] - 85s 11ms/step - loss: 0.1477 - acc: 0.9461 - val_loss: 0.3042 - val_acc: 0.9087\n",
            "Epoch 13/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1479 - acc: 0.9456 - val_loss: 0.2992 - val_acc: 0.8962\n",
            "Epoch 14/50\n",
            "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1296 - acc: 0.9478 - val_loss: 0.3569 - val_acc: 0.9067\n",
            "Epoch 15/50\n",
            "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1254 - acc: 0.9527 - val_loss: 0.2828 - val_acc: 0.9053\n",
            "Epoch 16/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1269 - acc: 0.9484 - val_loss: 0.3397 - val_acc: 0.9070\n",
            "Epoch 17/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1322 - acc: 0.9463 - val_loss: 0.6985 - val_acc: 0.8405\n",
            "Epoch 18/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1344 - acc: 0.9474 - val_loss: 0.3566 - val_acc: 0.9023\n",
            "Epoch 19/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1430 - acc: 0.9472 - val_loss: 0.2664 - val_acc: 0.9080\n",
            "Epoch 20/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1179 - acc: 0.9509 - val_loss: 0.3131 - val_acc: 0.9033\n",
            "Epoch 21/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1115 - acc: 0.9538 - val_loss: 0.2892 - val_acc: 0.9114\n",
            "Epoch 22/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1522 - acc: 0.9452 - val_loss: 0.6839 - val_acc: 0.8225\n",
            "Epoch 23/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1860 - acc: 0.9366 - val_loss: 0.3014 - val_acc: 0.9131\n",
            "Epoch 24/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1394 - acc: 0.9483 - val_loss: 0.4062 - val_acc: 0.8846\n",
            "Epoch 25/50\n",
            "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1522 - acc: 0.9461 - val_loss: 0.2641 - val_acc: 0.9063\n",
            "Epoch 26/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1686 - acc: 0.9316 - val_loss: 0.2770 - val_acc: 0.9104\n",
            "Epoch 27/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1319 - acc: 0.9457 - val_loss: 0.2701 - val_acc: 0.9216\n",
            "Epoch 28/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1252 - acc: 0.9476 - val_loss: 0.3095 - val_acc: 0.9135\n",
            "Epoch 29/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1162 - acc: 0.9509 - val_loss: 0.3162 - val_acc: 0.9108\n",
            "Epoch 30/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1136 - acc: 0.9525 - val_loss: 0.3446 - val_acc: 0.9097\n",
            "Epoch 31/50\n",
            "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1188 - acc: 0.9506 - val_loss: 0.3451 - val_acc: 0.9060\n",
            "Epoch 32/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1279 - acc: 0.9446 - val_loss: 0.2543 - val_acc: 0.9121\n",
            "Epoch 33/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1220 - acc: 0.9505 - val_loss: 0.3023 - val_acc: 0.9131\n",
            "Epoch 34/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1174 - acc: 0.9517 - val_loss: 0.2523 - val_acc: 0.9192\n",
            "Epoch 35/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1126 - acc: 0.9512 - val_loss: 0.2716 - val_acc: 0.9209\n",
            "Epoch 36/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1196 - acc: 0.9502 - val_loss: 0.9667 - val_acc: 0.8147\n",
            "Epoch 37/50\n",
            "7352/7352 [==============================] - 81s 11ms/step - loss: 0.1484 - acc: 0.9434 - val_loss: 0.2595 - val_acc: 0.9274\n",
            "Epoch 38/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1660 - acc: 0.9393 - val_loss: 0.3924 - val_acc: 0.9009\n",
            "Epoch 39/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1151 - acc: 0.9542 - val_loss: 0.3334 - val_acc: 0.9050\n",
            "Epoch 40/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1164 - acc: 0.9513 - val_loss: 0.3485 - val_acc: 0.9009\n",
            "Epoch 41/50\n",
            "7352/7352 [==============================] - 87s 12ms/step - loss: 0.1135 - acc: 0.9528 - val_loss: 0.3152 - val_acc: 0.9063\n",
            "Epoch 42/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.2148 - acc: 0.9338 - val_loss: 0.3124 - val_acc: 0.9097\n",
            "Epoch 43/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1959 - acc: 0.9319 - val_loss: 0.2954 - val_acc: 0.9067\n",
            "Epoch 44/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.2483 - acc: 0.9129 - val_loss: 0.3808 - val_acc: 0.9013\n",
            "Epoch 45/50\n",
            "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1501 - acc: 0.9463 - val_loss: 0.2747 - val_acc: 0.9206\n",
            "Epoch 46/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1351 - acc: 0.9479 - val_loss: 0.2812 - val_acc: 0.9250\n",
            "Epoch 47/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1438 - acc: 0.9459 - val_loss: 0.2583 - val_acc: 0.9101\n",
            "Epoch 48/50\n",
            "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1217 - acc: 0.9508 - val_loss: 0.2604 - val_acc: 0.9128\n",
            "Epoch 49/50\n",
            "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1182 - acc: 0.9527 - val_loss: 0.2593 - val_acc: 0.9257\n",
            "Epoch 50/50\n",
            "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1187 - acc: 0.9501 - val_loss: 0.2575 - val_acc: 0.9213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20201e44e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwoECRkMgr4f",
        "colab_type": "code",
        "outputId": "01fc8a9c-e0b8-40b9-daaf-bd776df66e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score=model_5.evaluate(X_test,Y_test,verbose=0)\n",
        "print(\"Loss =\",score[0],\" Accuracy =\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.25753965879978535  Accuracy = 0.9212758737699356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFhOCm7u-rIZ",
        "colab_type": "code",
        "outputId": "d56abe41-89cc-4c72-969a-e5fb50fe24c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model_5.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 537        0  ...                   0                 0\n",
            "SITTING                  1      373  ...                   1                 2\n",
            "STANDING                 0       71  ...                   0                 1\n",
            "WALKING                  0        0  ...                   0                29\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 417                 2\n",
            "WALKING_UPSTAIRS         0        0  ...                   6               461\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j54GUqjOuJCs",
        "colab_type": "text"
      },
      "source": [
        "#======================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIXdT2vjuMvg",
        "colab_type": "code",
        "outputId": "40abeb21-60ac-4864-a131-a586cde36936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "import seaborn as sns\n",
        "table=PrettyTable()\n",
        "table.field_names=(\"M0del\",\"Test Loss\",\"Test Accuracy\")\n",
        "\n",
        "table.add_row((\"Model-1\",0.40,0.87))\n",
        "table.add_row((\"Model-2\",0.49,0.87))\n",
        "table.add_row((\"Model-3\",0.43,0.87))\n",
        "table.add_row((\"Model-4\",0.38,0.90))\n",
        "table.add_row((\"Model-5 with 2 LSTM Layers and 32 cells each\",0.37,0.90))\n",
        "table.add_row((\"Model-6 with 2 LSTM Layers and 64 cells each\",0.25,0.92))\n",
        "print(table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------+-----------+---------------+\n",
            "|                    M0del                     | Test Loss | Test Accuracy |\n",
            "+----------------------------------------------+-----------+---------------+\n",
            "|                   Model-1                    |    0.4    |      0.87     |\n",
            "|                   Model-2                    |    0.49   |      0.87     |\n",
            "|                   Model-3                    |    0.43   |      0.87     |\n",
            "|                   Model-4                    |    0.25   |      0.92     |\n",
            "| Model-5 with 2 LSTM Layers and 32 cells each |    0.37   |      0.9      |\n",
            "| Model-6 with 2 LSTM Layers and 64 cells each |    0.36   |      0.9      |\n",
            "+----------------------------------------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V6nlD2T2GM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}